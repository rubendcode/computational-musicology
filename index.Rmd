---
title: "Corpus Ruben Dijksma"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    self_contained: false
    source: https://github.com/rubendcode/computational-musicology/blob/main/index.Rmd
    css: css_file.css
    theme:
      heading_font:
        google: 
          family: Rajdhani
          wght: 700
      base_font:
        google: Fira Sans
      code_font:
        google: Fira Mono
      bg: "#FFFFFF"
      fg: "#212529" 
      primary: "#2b2bee"
      secondary: "#39d7b8"
      success: "#39d7b8"
      danger: "#fa5577"
      warning: "#ffb14c"
      info: "#0cc7f1"
date: "2024-02-23"
---

```{r setup, include=FALSE}
library(tidyverse)
library(tidymodels)
library(plotly)
library(heatmaply)
library(protoclust)
library(cowplot)
library(spotifyr)
library(htmltools)
library(compmus)
library(gridExtra)
library(cowplot)

knitr::opts_chunk$set(cache = TRUE, cache.lazy = FALSE)
```

### Introduction

When do we call a pop song an indiepop song? In the beginning of 2024, the famous 2000’s pop song ‘[Murder On The Dancefloor](https://open.spotify.com/track/4tKGFmENO69tZR9ahgZu48?si=71cdf97637894cf9)’ by Sophie Ellis-Bextor has been rediscovered by TikTok after the movie Saltburn came out. The song was covered by ‘indie-pop’ duo [Royel Otis](https://open.spotify.com/track/1swz9stsbG1p34SJHJqiww?si=aedffd73d0e943d8). After the cover, the song turned into a timeless indiepop song with sounds from the 2010’s. As a musician, myself heavily inspired by the indie-pop style I am more than interested to discover what musical components make a regular pop song differ from an indie-pop song that makes me and many others feel a certain nostalgic way. 

My corpus is genre-based but I plan to analyze artists, songs, playlists, and charts with this research question. I hope to be able to discover when Spotify recognizes songs within Spotify as ‘indie-pop’, ‘pop’, or maybe in some cases both. I am not sure how deep we can analyze the song's components (chords, scales etc.) or just the metadata around it. I plan to get the tracks from playlists as “Indie Pop”, “Indie Pop Hits” and “Pop Rising” curated by Spotify. Specific tracks I want to look at are current “pop” hits such as “[Flowers](https://open.spotify.com/track/7DSAEUvxU8FajXtRloy8M0?si=9ec9d7ad18204823)” by Miley Cyrus and “[Greedy](https://open.spotify.com/track/3rUGC1vUpkDG9CZFHMur1t?si=0cfe0fafb0964e81)” by Tate McRae and current “indie pop” hits such as the [Murder On The Dancefloor](https://open.spotify.com/track/1swz9stsbG1p34SJHJqiww?si=aedffd73d0e943d8) cover by Royel Otis and a classic as Kilby Girl by The Backseat Lovers.

**How do indie-pop songs stand out from pop songs when we look at them through the Spotify API?** This question is at the heart of my study. I want to figure out what makes these two genres different.

------------------------------------------------------------------------

This flexdashboard will show multiple graphs and discussions about the difference in genre.

### Energy vs Acousticness

How do Energy and Acousticness compare in Indiepop and Pop genres?

For the first graphs I made 2 graphs with the energy on the X axis and the acousticness on the Y axis. 
I chose these two variables since acousticness and energy are what in my mind differentiate the two genres. 

I used the indie pop and the pop party playlist with both graphs showing that indie pop is in general more acoustic and pop more energetic. These two scatterplots are only representing two playlists so to properly see the difference I would need to add more playlists in my corpus. 

```{r echo=FALSE, out.width = '100%', fig.width = 4, fig.height = 6}
library(tidyverse)
library(spotifyr)

# Fetch audio features for playlists
indiepop <- get_playlist_audio_features("", "37i9dQZF1DWWEcRhUVtL8n?si=8549c3d965e4458c&nd=1&dlsi=7e635eb660464a36")
pop <- get_playlist_audio_features("", "37i9dQZF1DWXti3N4Wp5xy?si=e0a5344cb1b545c5&nd=1&dlsi=61886b9565ee4c74")

# Combine playlists into a single data frame
music <- bind_rows(
  indiepop %>% mutate(category = "Indie Pop Playlist"),
  pop %>% mutate(category = "Pop Playlist")
)

# Create the ggplot object
ggplot_obj <- ggplot(music, aes(x = energy, y = acousticness)) +
  geom_point(aes(color = category), alpha = 0.7) +
  facet_wrap(~category) +
  labs(x = "Energy", y = "Acousticness") +
  theme_minimal()

# Render the plot using ggplotly to ensure proper display
div(
  ggplotly(ggplot_obj),
  style = "width: 900px; height: 600px; overflow: scroll;"
)

```

------------------------------------------------------------------------

For these graphs I used these playlists:

```{r echo=FALSE}
library(htmltools)

div(
  HTML('<iframe src="https://open.spotify.com/embed/playlist/37i9dQZF1DWWEcRhUVtL8n?utm_source=generator" width="100%" height="390" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>')
)

div(
  HTML('<iframe src="https://open.spotify.com/embed/playlist/37i9dQZF1DWXti3N4Wp5xy?utm_source=generator" width="100%" height="390" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>')
)

```

### Chromagrams Murder On The Dancefloor

```{r chromagrams, echo=FALSE}


library(cowplot)

royelotis <- get_tidy_audio_analysis("1swz9stsbG1p34SJHJqiww") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches) |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(title = "Royel Otis Murder On The Dancefloor", x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

Sophie <- get_tidy_audio_analysis("4tKGFmENO69tZR9ahgZu48") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches) |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(title = "Sophie Ellis-Bextor Murder On The Dancefloor", x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()


# Arrange the plots in a grid layout with synchronized x-axis scales
grid <- plot_grid(royelotis, Sophie, nrow = 2, align = "hv", scale = c(1, 1)) # Adjust the relative width here

# Display the combined plot
grid


```

------------------------------------------------------------------------

How do the chromagrams of an original pop song and an indiepop cover song differentiate?

The chromagrams show that both tracks are in the same key. I think it is interesting to see that the E note is really present in the Royel Otis (indie) version and less in the version from Sophie. The C# is being played more (as a harmonic I assume) in the Sophie version. 

One of the biggest differences of the two songs is that the version of Sophie is a studio recording while the version from Royel Otis is live. There seem to be more harmonics in the Sophie version. The magnitude is higher in most notes in the Royel Otis version. I would expect there to be more magnitude in a well recorded studio version. This is something I want to look into further.

### Cepstograms

```{r timbres, echo=FALSE}
library(cowplot)
library(compmus)

# Define function to create cepstogram plot
create_cepstogram_plot <- function(audio_uri, title) {
  audio_data <- get_tidy_audio_analysis(audio_uri)
  
  cepstogram_data <- audio_data %>%
    compmus_align(bars, segments) %>%
    select(bars) %>%
    unnest(bars) %>%
    mutate(
      pitches = map(segments, compmus_summarise, pitches, method = "rms", norm = "euclidean"),
      timbre = map(segments, compmus_summarise, timbre, method = "rms", norm = "euclidean")
    )
  
  cepstogram_plot <- cepstogram_data %>%
    compmus_gather_timbre() %>%
    ggplot(
      aes(
        x = start + duration / 2,
        width = duration,
        y = basis,
        fill = value
      )
    ) +
    geom_tile() +
    labs(title = title, x = "Time (s)", y = NULL, fill = "Magnitude") +
    scale_fill_viridis_c() +
    theme_classic() +
    theme(plot.title = element_text(size = 8))  # Adjust title size
  
  return(cepstogram_plot)
}

# Create cepstogram plots for Royel Otis and Sophie Ellis-Bextor
royelotis_cepstogram_plot <- create_cepstogram_plot("1swz9stsbG1p34SJHJqiww", "Royel Otis Murder On The Dancefloor")
sophie_cepstogram_plot <- create_cepstogram_plot("4tKGFmENO69tZR9ahgZu48", "Sophie Ellis-Bextor Murder On The Dancefloor")

# Arrange the plots side by side with smaller scale
cepstogram_grid <- plot_grid(
  royelotis_cepstogram_plot + theme(plot.margin = margin(10, 10, 10, 10)),  # Adjust plot margin
  sophie_cepstogram_plot + theme(plot.margin = margin(10, 10, 10, 10)),  # Adjust plot margin
  ncol = 1, align = "h", scale = 1  # Arrange plots side by side with smaller scale
)

# Display the combined plot grid
cepstogram_grid


```

------------------------------------------------------------------------

How do the cepstograms of an original pop song and an indiepop cover song differentiate?

For the next part of the analysis I decided to do a timbre analysis on both songs. I plotted two cepstograms where Sophie's version shows a more clear timbre outline. Instead of the Royel Otis version where only at the end there is a high magnitude. 

These show that there is 'more' timbre in the original version from Sophie. This might be because the Royel Otis song was recorded as a live song while the original pop song was recorded in a proper studio. 

### Chordograms of Corpus

```{r}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )


# Function to create chordogram plots
create_chordogram_plot <- function(audio_uri, title) {
  audio_data <- get_tidy_audio_analysis(audio_uri)
  
  chord_data <- audio_data %>%
    compmus_align(sections, segments) %>%
    select(sections) %>%
    unnest(sections) %>%
    mutate(
      pitches = map(segments, compmus_summarise, pitches, method = "mean", norm = "manhattan")
    )
  
  chord_plot <- chord_data %>%
    compmus_match_pitch_template(chord_templates, method = "euclidean", norm = "manhattan") %>%
    ggplot(
      aes(x = start + duration / 2, width = duration, y = name, fill = d)
    ) +
    geom_tile() +
    labs(title = title, x = "Time (s)", y = NULL, fill = "Magnitude") +
    scale_fill_viridis_c(guide = "none") +
    theme_minimal() +
    labs(x = "Time (s)", y = "")
  
  return(chord_plot)
}


royel_otis_plot <- create_chordogram_plot("1swz9stsbG1p34SJHJqiww", "Royel Otis Murder On The Dancefloor")
sophie_plot <- create_chordogram_plot("4tKGFmENO69tZR9ahgZu48", "Sophie Ellis-Bextor")

royel_otis_plot <- royel_otis_plot + theme(
  plot.margin = unit(c(1,1,1,1), "cm"), # Adjust margins (top, right, bottom, left)
  text = element_text(size = 10) # Adjust text size
)

sophie_plot <- sophie_plot + theme(
  plot.margin = unit(c(1,1,1,1), "cm"),
  text = element_text(size = 10)
)

# Now, arrange the plots in a grid layout without overlapping
chordogram_grid <- plot_grid(
  royel_otis_plot, sophie_plot,
  nrow = 1, align = "hv", scale = c(1, 1)
)

# Display the combined plot grid
chordogram_grid

```

***


How do the chords of an original pop song and an indiepop cover song differentiate?

The chordogram is not able to recognise the chords in the indiepop song as well as in the pop song. 
In the version of Sophie Ellis-Bextor there is a clear chord structure of chords in the intro and at the 175 second mark. It includes a clear view of Bbmaj and Gmin. At the end of the Royel Otis song there is last guitar strum that picks up the chordogram well. It is a Bbmaj chord but all chords in the scale get recognised. 


### Playlist Key Comparisons

```{r}
library(ggplot2)
library(gridExtra)

# Load necessary libraries
library(dplyr)

# Define function to fetch playlist audio features and add audio analysis
get_and_analyze_playlist <- function(playlist_id, playlist_name) {
  playlist_features <- get_playlist_audio_features("thesoundsofspotify", playlist_id) %>%
    slice(1:50) %>%
    add_audio_analysis() %>%
    mutate(playlist_name = playlist_name)
  return(playlist_features)
}

# Function to extract keys and modes from audio features
extract_keys_and_modes <- function(audio_features) {
  # Convert integer key values to character key names
  key_names <- c("C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B")
  keys <- factor(key_names[audio_features$key])
  modes <- factor(ifelse(audio_features$mode == 0, "Minor", "Major"))
  return(list(keys = keys, modes = modes))
}

# Fetch audio features and analyze playlists for pop and indiepop
#pop <- get_and_analyze_playlist("37i9dQZF1DWXti3N4Wp5xy", "Pop")
#indiepop <- get_and_analyze_playlist("37i9dQZF1DWWEcRhUVtL8n", "Indie Pop")

# Extract keys and modes for each playlist
pop_keys_modes <- extract_keys_and_modes(pop)
indiepop_keys_modes <- extract_keys_and_modes(indiepop)

# Define all 12 possible keys
all_keys <- factor(c("C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"))

# Make sure both playlists have the same number of keys
num_keys <- max(length(pop_keys_modes$keys), length(indiepop_keys_modes$keys))
pop_keys <- rep(pop_keys_modes$keys, length.out = num_keys)
pop_modes <- rep(pop_keys_modes$modes, length.out = num_keys)
indiepop_keys <- rep(indiepop_keys_modes$keys, length.out = num_keys)
indiepop_modes <- rep(indiepop_keys_modes$modes, length.out = num_keys)

# Create data frames for Pop and Indie Pop playlists
pop_df <- data.frame(Key = factor(pop_keys, levels = all_keys), Mode = pop_modes, Playlist = "Pop")
indiepop_df <- data.frame(Key = factor(indiepop_keys, levels = all_keys), Mode = indiepop_modes, Playlist = "Indie Pop")

# Combine data frames
combined_df <- rbind(pop_df, indiepop_df)

# Plot histograms for major keys
major_df <- combined_df %>% filter(Mode == "Major")
plot_major <- ggplot(major_df, aes(x = Key, fill = Playlist)) +
  geom_bar(stat = "count", position = "dodge", width = 0.7) +
  labs(
    x = "Key",
    y = "Frequency",
    title = "Histogram of Major Keys for Pop and Indie Pop Playlists"
  ) +
  scale_fill_manual(values = c("Pop" = "skyblue", "Indie Pop" = "salmon")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Plot histograms for minor keys
minor_df <- combined_df %>% filter(Mode == "Minor")
plot_minor <- ggplot(minor_df, aes(x = Key, fill = Playlist)) +
  geom_bar(stat = "count", position = "dodge", width = 0.7) +
  labs(
    x = "Key",
    y = "Frequency",
    title = "Histogram of Minor Keys for Pop and Indie Pop Playlists"
  ) +
  scale_fill_manual(values = c("Pop" = "skyblue", "Indie Pop" = "salmon")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Assuming combined_df contains the combined data for both playlists
# Assuming combined_df contains the combined data for both playlists

# Count the number of major and minor keys in each playlist
major_minor_count_per_playlist <- combined_df %>%
  group_by(Playlist, Mode) %>%
  summarise(Count = n()) %>%
  pivot_wider(names_from = Mode, values_from = Count, values_fill = list(Count = 0))


# Arrange plots in a grid
grid <- grid.arrange(plot_major, plot_minor, ncol = 1)


```

------------------------------------------------------------------------
The chart for major keys shows that C major (C) is the most frequent key in both pop and indie pop playlists, followed by G major (G) and A major (A). There is a higher frequency of major keys in both pop and indie pop playlists compared to minor keys.

The chart for minor keys shows that A minor (Am) is the most frequent key in both pop and indie pop playlists, followed by G minor (Gm) and Em minor (Em). Overall, the data suggests that major keys are more common in both pop and indie pop playlists than minor keys. This aligns with the general perception of pop and indie pop music as being upbeat and positive.

There seem to be no indie pop songs in the key of A# major and minor in the sample. Just like there are more songs in minor on the A, F# and E minor scale.

### Boxplots of Tempo

```{r }

# Load necessary libraries
library(ggplot2)
library(dplyr)

# Assuming you have the data for the two playlists stored in pop_df and indiepop_df

pop_party <- get_and_analyze_playlist("37i9dQZF1DWXti3N4Wp5xy", "Pop Party")
fresh_pop <- get_and_analyze_playlist("37i9dQZF1DX2fMaj5GfMh3", "Fresh Pop")

#indiepop <- get_and_analyze_playlist("37i9dQZF1DWWEcRhUVtL8n", "Indie Pop")
diff_indie <- get_and_analyze_playlist("37i9dQZF1DXad2sxzzYX1N", "Indie That Hits Different")

# Combine the data into one dataframe
combined_df <- rbind(
  data.frame(Playlist = "Pop Party", tempo = pop_party$tempo),
  data.frame(Playlist = "Fresh Pop", tempo = fresh_pop$tempo),
  data.frame(Playlist = "Indie Pop", tempo = indiepop$tempo),
  data.frame(Playlist = "Indie That Hits Different", tempo = diff_indie$tempo)
)

# Create boxplot to compare tempo across playlists
ggplot(combined_df, aes(x = Playlist, y = tempo, fill = Playlist)) +
  geom_boxplot() +
  labs(
    title = "Comparison of Tempo Across Playlists",
    x = "Playlist",
    y = "Tempo"
  ) +
  scale_fill_manual(values = c("skyblue", "salmon", "green", "purple")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


***

To see if these pop and indiepop playlists are that different from each other I decided to add two more playlists (Fresh Pop and Indie That Hits Different). It is interesting to see that the range of the two indie pop playlists is really similar and the two pop playlists are too. It seems like there is a correlation in this difference in the two genres. 
Q1 and Q3 are in a wider range from each other in both playlists while in the Pop playlists they are closer to each other. 

The Pop playlists have multiple outliers that are either around 175 or 80. It seems like this is the case since the average is closer to each other Q1 and Q3. In the next page there are Tempograms to see this better.

### Time Signature in different playlists

```{r }

# Load necessary libraries
library(ggplot2)
library(dplyr)

# Assuming you have the data for the two playlists stored in pop_df and indiepop_df
# I'll just create sample data for demonstration purposes

pop_party <- get_and_analyze_playlist("37i9dQZF1DWXti3N4Wp5xy", "Pop Party")
fresh_pop <- get_and_analyze_playlist("37i9dQZF1DX2fMaj5GfMh3", "Fresh Pop")
indiepop <- get_and_analyze_playlist("37i9dQZF1DWWEcRhUVtL8n", "Indie Pop")
diff_indie <- get_and_analyze_playlist("37i9dQZF1DXad2sxzzYX1N", "Indie That Hits Different")

# Combine the data into one dataframe
combined_df <- rbind(
  data.frame(Playlist = "Pop Party", time_signature = pop_party$time_signature),
  data.frame(Playlist = "Fresh Pop", time_signature = fresh_pop$time_signature),
  data.frame(Playlist = "Indie Pop", time_signature = indiepop$time_signature),
  data.frame(Playlist = "Indie That Hits Different", time_signature = diff_indie$time_signature)
)

# Create histogram to compare time signatures across playlists
ggplot(combined_df, aes(x = time_signature, fill = Playlist)) +
  geom_histogram(binwidth = 0.5, position = "dodge") +
  labs(
    title = "Comparison of Time Signatures Across Playlists",
    x = "Time Signature",
    y = "Count"
  ) +
  scale_fill_manual(values = c("skyblue", "salmon", "green", "purple")) +
  theme_minimal()

```

***

I wanted to see if there are big differences in time signatures within both genres. 
There are a few more songs in 3/4 in indie pop then there are in pop playlists. 
I would have expected this difference to be bigger.

### Tempogram Outliers In Pop Playlists

```{r }
library(cowplot)

# Load the audio analysis data
drunktext <- get_tidy_audio_analysis("0KpWiHVmIFDTvai20likX4")
alibi <- get_tidy_audio_analysis("4JyS3WGxalmpzgEbVyTycL")
blinding_lights <- get_tidy_audio_analysis("0VjIjW4GlUZAMYd2vXMi3b")

# Function to create tempogram plot
create_tempogram_plot <- function(data, title) {
  data |>
    tempogram(window_size = 8, hop_size = 1, cyclic = FALSE) |>
    ggplot(aes(x = time, y = bpm, fill = power)) +
    geom_raster() +
    scale_fill_viridis_c(guide = "none") +
    labs(title = title, x = "Time (s)", y = "Tempo (BPM)") +
    theme_classic()
}

# Create tempogram plots
plot_drunktext <- create_tempogram_plot(drunktext, "drunk text - Henry Moodie")
plot_alibi <- create_tempogram_plot(alibi, "The Alibi - Dylan")
plot_blinding_lights <- create_tempogram_plot(blinding_lights, "Blinding Lights - The Weeknd")

# Arrange the plots in a grid
grid <- plot_grid(plot_drunktext, plot_alibi, plot_blinding_lights, nrow = 2)

# Display the combined plot grid
grid


```

*** 
How do the outliers of the tempo analysis compare with the real tempo in the tempograms?

In the boxplot analysis there were outliers in the Pop playlists. After analyzing these songs it was clear that they were indeed just outliers. The tempo of these songs are constant. Drunk text by Henry Moodie has a BPM of 186. 

What can be the reason for these songs to be outliers is that songs are getting faster and 'pop' is getting faster by the time. This could be a good question for future research. 

### Classification and Clustering

```{r }

library(ggdendro)
library(heatmaply)

library(compmus)

get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit |> 
    collect_predictions() |> 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit |> 
    conf_mat_resampled() |> 
    group_by(Prediction) |> mutate(precision = Freq / sum(Freq)) |> 
    group_by(Truth) |> mutate(recall = Freq / sum(Freq)) |> 
    ungroup() |> filter(Prediction == Truth) |> 
    select(class = Prediction, precision, recall)
}  

oyster <-
  get_playlist_audio_features("oystercollection", "37i9dQZF1DWWEcRhUVtL8n") |>
  add_audio_analysis() |>
  mutate(
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) |>
  mutate(pitches = map(pitches, compmus_normalise, "clr")) |>
  mutate_at(vars(pitches, timbre), map, bind_rows) |>
  unnest(cols = c(pitches, timbre))

# Select only 40 songs
oyster <- slice(oyster, 1:40)

oyster_juice <-
  recipe(
    track.name ~
      danceability +
      energy +
      loudness +
      acousticness +
      instrumentalness +
      valence +
      tempo +
      duration,
    data = oyster
  ) |>
  step_center(all_predictors()) |>
  step_scale(all_predictors()) |> 
  # step_range(all_predictors()) |> 
  prep(oyster |> mutate(track.name = str_trunc(track.name, 20))) |>
  juice() |>
  column_to_rownames("track.name")

oyster_dist <- dist(oyster_juice, method = "euclidean")

heatmaply(
  oyster_juice,
  hclustfun = hclust,
  hclust_method = "average",  # Change for single, average, or complete linkage.
  dist_method = "euclidean"
)

```

*** 
How do the songs in an indiepop playlist cluster together?

I did a random selection for clustering of 40 song of the Indie Pop playlist. The dendrogram on the left shows how songs are grouped together based on similarity across these attributes. Clusters in a dendrogram indicate songs that are similar to each other in the context of the attributes included in the analysis.
Not suprisingly loudness and energy are clustered together. 

A song that stood out to me was is Jesus is dead that has a high instrumentalness and is alone in it's cluster. Even though indiepop songs are overall all high in instrumentalness the song gets picked up as high in instrumentalness. 


### Conclusion & Discussion

In my project, I used a variety of methods to explore the unique qualities of indie pop music compared to mainstream pop. Using the Spotify API, I gathered data on songs' features like their energy, how acoustic they are, and their tempo. This allowed me to analyze the music deeply, beyond just listening.

I created chordograms to understand the chords used in songs. This was fascinating because it showed how indie pop songs might use chords differently, making them sound unique. Similarly, looking at chromagrams helped me see the notes and keys that are more common in indie pop. Through cepstograms, I examined the timbre of songs, which is like looking at their color or texture in terms of sound.

The Spotify API was crucial because it let me get detailed information about songs that you can't find just by listening. This included things like the song's tempo, how loud it is, and its mood (valence).

One interesting finding was when I compared the tempo of songs in different playlists. Indie pop songs had a wider range of tempos, suggesting more variety in how they feel and move. On the other hand, mainstream pop songs tended to stick to a more narrow range of tempos.

Looking at time signatures was another eye-opener. Indie pop songs were more likely to experiment with different time signatures, which can give a song an unusual rhythm or feel.

For future research, I'm curious to dive deeper into how indie pop evolves. Are there trends in the genre that are becoming more popular? Also, I wonder how technological changes will affect indie pop music. With new tools and platforms, indie artists have more opportunities to experiment and share their music. It would be interesting to see how this shapes the genre.

In summary, my project taught me a lot about the subtleties that make indie pop distinct from mainstream pop. By using data from the Spotify API and analyzing it with various methods, I've gained a richer understanding of what makes each genre unique. Looking ahead, I'm excited to see where indie pop will go and how it will continue to evolve.
